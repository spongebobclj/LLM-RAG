{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¯¼å…¥ç›¸å…³çš„åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from zhipuai import ZhipuAI\n",
    "from typing import Dict, Any, Mapping\n",
    "from pydantic import Field\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional, Dict, Union, Tuple\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import matplotlib.image as mpimg\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import cv2\n",
    "import requests\n",
    "import os\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import LLMRequestsChain\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from __future__ import annotations\n",
    "import logging\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.pydantic_v1 import BaseModel, root_validator\n",
    "from langchain.utils import get_from_dict_or_env\n",
    "from paddleocr import PaddleOCR\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è‡ªå®šä¹‰ç›¸å…³çš„LLMç±»ï¼šå®šä¹‰äº†ä¸€ä¸ªåä¸º Self_LLM çš„è‡ªå®šä¹‰ LLM ç±»ï¼Œè¯¥ç±»ç»§æ‰¿è‡ª LLMã€‚ç±»åŒ…å«è®¿é—® URLã€æ¨¡å‹åç§°ã€è¯·æ±‚è¶…æ—¶ã€æ¸©åº¦ç³»æ•°ã€API å¯†é’¥å’Œé¢å¤–å‚æ•°ã€‚æä¾›äº†ä¸€ä¸ªæ–¹æ³•è¿”å›é»˜è®¤è°ƒç”¨å‚æ•°ï¼ŒåŒ…æ‹¬æ¸©åº¦å’Œè¯·æ±‚è¶…æ—¶ï¼Œå¹¶å°†è¿™äº›å‚æ•°ä¸æ¨¡å‹å‚æ•°åˆå¹¶ã€‚å¦ä¸€ä¸ªæ–¹æ³•è¿”å›è¯†åˆ«å‚æ•°ï¼Œå°†æ¨¡å‹åç§°ä¸é»˜è®¤å‚æ•°åˆå¹¶ã€‚è¿™ä¸ªç±»ç”¨äºçµæ´»é…ç½®å’Œè®¿é—®è‡ªå®šä¹‰ LLM æ¨¡å‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_LLM(LLM):\n",
    "    # è‡ªå®šä¹‰ LLM\n",
    "    url: str = \"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={api_key}&client_secret={secret_key}\"\n",
    "    model_name: str = \"gpt-3.5-turbo\"\n",
    "    # è®¿é—®æ—¶å»¶ä¸Šé™\n",
    "    request_timeout: float = None\n",
    "    # æ¸©åº¦ç³»æ•°\n",
    "    temperature: float = 0.1\n",
    "    api_key: str = None\n",
    "    model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    # å®šä¹‰ä¸€ä¸ªè¿”å›é»˜è®¤å‚æ•°çš„æ–¹æ³•\n",
    "    @property\n",
    "    def _default_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–è°ƒç”¨é»˜è®¤å‚æ•°ã€‚\"\"\"\n",
    "        normal_params = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"request_timeout\": self.request_timeout,\n",
    "        }\n",
    "        # print(type(self.model_kwargs))\n",
    "        return {**normal_params}\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {**{\"model_name\": self.model_name}, **self._default_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è‡ªå®šä¹‰ç›¸å…³çš„æ–‡å¿ƒå¤§æ¨¡å‹ï¼šé€šè¿‡ç›¸å…³çš„apikeyå’Œsecretkeyå¾—åˆ°å¯¹åº”çš„access tokenï¼Œå¹¶ä¸”é€šè¿‡access_tokenå‘æ–‡å¿ƒä¸€è¨€çš„APIåœ°å€å‘èµ·è¯·æ±‚ï¼Œæœ€ç»ˆå¾—åˆ°ç›¸åº”çš„æœåŠ¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token(api_key: str, secret_key: str):\n",
    "\n",
    "    url = f\"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={api_key}&client_secret={secret_key}\"\n",
    "    payload = json.dumps(\"\")\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    return response.json().get(\"access_token\")\n",
    "\n",
    "\n",
    "class Wenxin_LLM(Self_LLM):\n",
    "    # æ–‡å¿ƒå¤§æ¨¡å‹çš„è‡ªå®šä¹‰ LLM\n",
    "    url: str = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/ernie-4.0-turbo-8k?access_token={}\"\n",
    "    # Secret_Key\n",
    "    secret_key: str = None\n",
    "    # access_token\n",
    "    access_token: str = None\n",
    "\n",
    "    def init_access_token(self):\n",
    "        if self.api_key != None and self.secret_key != None:\n",
    "            try:\n",
    "                self.access_token = get_access_token(self.api_key, self.secret_key)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"è·å– access_token å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Key\")\n",
    "        else:\n",
    "            print(\"API_Key æˆ– Secret_Key ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ Key\")\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None,\n",
    "              run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "              **kwargs: Any):\n",
    "        # å¦‚æœ access_token ä¸ºç©ºï¼Œåˆå§‹åŒ– access_token\n",
    "        if self.access_token == None:\n",
    "            self.init_access_token()\n",
    "        # API è°ƒç”¨ url\n",
    "        url = self.url.format(self.access_token)\n",
    "        # é…ç½® POST å‚æ•°\n",
    "        payload = json.dumps({\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",  # user prompt\n",
    "                    \"content\": \"{}\".format(prompt)  # è¾“å…¥çš„ prompt\n",
    "                }\n",
    "            ],\n",
    "            'temperature': self.temperature\n",
    "        })\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        # å‘èµ·è¯·æ±‚\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload, timeout=self.request_timeout)\n",
    "        if response.status_code == 200:\n",
    "            js = json.loads(response.text)\n",
    "            print(js)\n",
    "            return js[\"result\"]\n",
    "        else:\n",
    "            return \"è¯·æ±‚å¤±è´¥\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Wenxin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æµ‹è¯•å¤§æ¨¡å‹apiæ˜¯å¦å¯ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# è·å–ç¯å¢ƒå˜é‡ OPENAI_API_KEY\n",
    "wenxin_api_key = os.environ[\"wenxin_api_key\"]\n",
    "wenxin_secret_key = os.environ[\"wenxin_secret_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'as-ibbafhmyq2', 'object': 'chat.completion', 'created': 1746586721, 'result': 'ä½ å¥½ï¼Œæˆ‘æ˜¯ç™¾åº¦å…¬å¸ç ”å‘çš„çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œæˆ‘çš„ä¸­æ–‡åæ˜¯æ–‡å¿ƒä¸€è¨€ï¼Œè‹±æ–‡åæ˜¯ERNIE Botï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼æˆ‘å¯ä»¥ä¸ºä½ è§£ç­”é—®é¢˜ã€åˆ›ä½œæ–‡æœ¬ã€è¿›è¡ŒçŸ¥è¯†æ¨ç†ï¼Œå¦‚æœä½ æœ‰éœ€è¦çš„è¯ï¼Œæˆ‘è¿˜å¯ä»¥è·Ÿä½ ä¸€èµ·èŠå¤©ã€åˆ†äº«ç¬‘è¯æˆ–è€…è®²æ•…äº‹ã€‚', 'is_truncated': False, 'need_clear_history': False, 'finish_reason': 'normal', 'usage': {'prompt_tokens': 1, 'completion_tokens': 51, 'total_tokens': 52}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½ï¼Œæˆ‘æ˜¯ç™¾åº¦å…¬å¸ç ”å‘çš„çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œæˆ‘çš„ä¸­æ–‡åæ˜¯æ–‡å¿ƒä¸€è¨€ï¼Œè‹±æ–‡åæ˜¯ERNIE Botï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼æˆ‘å¯ä»¥ä¸ºä½ è§£ç­”é—®é¢˜ã€åˆ›ä½œæ–‡æœ¬ã€è¿›è¡ŒçŸ¥è¯†æ¨ç†ï¼Œå¦‚æœä½ æœ‰éœ€è¦çš„è¯ï¼Œæˆ‘è¿˜å¯ä»¥è·Ÿä½ ä¸€èµ·èŠå¤©ã€åˆ†äº«ç¬‘è¯æˆ–è€…è®²æ•…äº‹ã€‚'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = Wenxin_LLM(api_key=wenxin_api_key, secret_key=wenxin_secret_key)\n",
    "llm(\"ä½ å¥½\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è‡ªå®šä¹‰ç›¸å…³çš„Zhipuçš„Embeddingç±»ï¼šé€šè¿‡åˆ©ç”¨Zhipu Embeddingè¿›è¡Œç›¸å…³çš„åµŒå…¥æ“ä½œï¼Œä»è€Œå®ç°åç»­å°†å·²æœ‰çŸ¥è¯†å­˜å…¥çŸ¥è¯†åº“çš„æ“ä½œï¼Œè¿™é‡Œçš„å®šä¹‰æ–¹æ³•è·Ÿä¸Šè¿°çš„æ–‡å¿ƒä¸€è¨€å¤§æ¨¡å‹ç›¸ä¼¼ï¼Œæ‰€ä»¥è¿™é‡Œå°±ä¸å†è¿‡å¤šçš„èµ˜è¿°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIEmbeddings(BaseModel, Embeddings):\n",
    "    \"\"\"`Zhipuai Embeddings` embedding models.\"\"\"\n",
    "\n",
    "    client: Any\n",
    "    \"\"\"`zhipuai.ZhipuAI\"\"\"\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        å®ä¾‹åŒ–ZhipuAIä¸ºvalues[\"client\"]\n",
    "\n",
    "        Args:\n",
    "\n",
    "            values (Dict): åŒ…å«é…ç½®ä¿¡æ¯çš„å­—å…¸ï¼Œå¿…é¡»åŒ…å« client çš„å­—æ®µ.\n",
    "        Returns:\n",
    "\n",
    "            values (Dict): åŒ…å«é…ç½®ä¿¡æ¯çš„å­—å…¸ã€‚å¦‚æœç¯å¢ƒä¸­æœ‰zhipuaiåº“ï¼Œåˆ™å°†è¿”å›å®ä¾‹åŒ–çš„ZhipuAIç±»ï¼›å¦åˆ™å°†æŠ¥é”™ 'ModuleNotFoundError: No module named 'zhipuai''.\n",
    "        \"\"\"\n",
    "        from zhipuai import ZhipuAI\n",
    "        from dotenv import find_dotenv, load_dotenv\n",
    "        import os\n",
    "        zhipu_api_key = os.environ[\"zhipu_api_key\"]\n",
    "\n",
    "        values[\"client\"] = ZhipuAI(api_key=zhipu_api_key)\n",
    "        return values\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆè¾“å…¥æ–‡æœ¬çš„ embedding.\n",
    "\n",
    "        Args:\n",
    "            texts (str): è¦ç”Ÿæˆ embedding çš„æ–‡æœ¬.\n",
    "\n",
    "        Return:\n",
    "            embeddings (List[float]): è¾“å…¥æ–‡æœ¬çš„ embeddingï¼Œä¸€ä¸ªæµ®ç‚¹æ•°å€¼åˆ—è¡¨.\n",
    "        \"\"\"\n",
    "        embeddings = self.client.embeddings.create(\n",
    "            model=\"embedding-2\",\n",
    "            input=text\n",
    "        )\n",
    "        # å•ä¸ªæ–‡æœ¬çš„ embedding æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å«ä¸€ä¸ªå­—å…¸ã€‚æ¯ä¸ªå­—å…¸éƒ½æœ‰ä¸€ä¸ª 'embedding' çš„é”®ï¼Œå…¶å€¼æ˜¯æµ®ç‚¹æ•°åˆ—è¡¨.\n",
    "        # å› æ­¤ï¼Œæˆ‘ä»¬ä»åˆ—è¡¨ä¸­å–å‡ºç¬¬ä¸€ä¸ªå…ƒç´ ï¼ˆå­—å…¸ï¼‰ï¼Œç„¶åä»è¿™ä¸ªå­—å…¸ä¸­è·å– 'embedding' çš„å€¼.\n",
    "        return embeddings.data[0].embedding\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        ç”Ÿæˆè¾“å…¥æ–‡æœ¬åˆ—è¡¨çš„ embedding.\n",
    "        Args:\n",
    "            texts (List[str]): è¦ç”Ÿæˆ embedding çš„æ–‡æœ¬åˆ—è¡¨.\n",
    "\n",
    "        Returns:\n",
    "            List[List[float]]: è¾“å…¥åˆ—è¡¨ä¸­æ¯ä¸ªæ–‡æ¡£çš„ embedding åˆ—è¡¨ã€‚æ¯ä¸ª embedding éƒ½è¡¨ç¤ºä¸ºä¸€ä¸ªæµ®ç‚¹å€¼åˆ—è¡¨ã€‚\n",
    "        \"\"\"\n",
    "        return [self.embed_query(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åŠ è½½ç›¸å…³çš„pdfæ–‡æ¡£ï¼Œç„¶åè¿›è¡Œç›¸å…³çš„æ–‡æ¡£åˆ‡åˆ†ï¼Œè¿™é‡Œä¸»è¦æ˜¯é’ˆå¯¹æˆ‘ä»¬æ”¶é›†åˆ°çš„pdfæ–‡æ¡£è¿›è¡Œç›¸å…³çš„åˆ‡åˆ†æ“ä½œï¼Œä»è€Œå®ç°äº†ç›¸å…³çš„æ•°æ®é¢„å¤„ç†çš„æ“ä½œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # æ˜¾ç¤ºè¿›åº¦æ¡\n",
    "from typing import List\n",
    "\n",
    "directory = './others/data/'\n",
    "# åŠ è½½ PDF\n",
    "loaders_chinese = []\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        loaders_chinese.append(PyMuPDFLoader(file_path))\n",
    "docs = []\n",
    "for loader in loaders_chinese:\n",
    "    docs.extend(loader.load())\n",
    "# åˆ‡åˆ†æ–‡æ¡£\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "embedding = ZhipuAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "print(len(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å¯æŒä¹…åŒ–çš„åœ°å€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './others/vector_db/chroma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åˆ é™¤åŸæ¥çš„å‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linux ä¸‹åˆ é™¤æ–‡ä»¶å¤¹\n",
    "# !rm -rf './others/vector_db/chroma'\n",
    "# windows ä¸‹åˆ é™¤æ–‡ä»¶å¤¹\n",
    "!rmdir /s /q \"./others/vector_db/chroma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å»ºç«‹ç›¸å…³çš„å‘é‡æ•°æ®åº“ï¼šåˆ©ç”¨Chromaç›¸å…³çš„å‡½æ•°å’Œå¯¹åº”çš„Embeddingç±»è¿›è¡Œå»ºç«‹ç›¸å…³çš„å‘é‡æ•°æ®åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs[:1000],\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory  # å…è®¸æˆ‘ä»¬å°†persist_directoryç›®å½•ä¿å­˜åˆ°ç£ç›˜ä¸Š\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ç»Ÿè®¡å‘é‡æ•°æ®åº“ä¸­å­˜å‚¨çš„æ•°é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‘é‡åº“ä¸­å­˜å‚¨çš„æ•°é‡ï¼š301\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "print(f\"å‘é‡åº“ä¸­å­˜å‚¨çš„æ•°é‡ï¼š{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å»ºç«‹ç›¸å…³çš„åŸºäºæ–‡å¿ƒä¸€è¨€å¤§æ¨¡å‹çš„LLMï¼Œ**RAG**æŠ€æœ¯çš„æ ¸å¿ƒä»£ç ï¼Œå¹¶ä¸”æˆ‘æ¨¡å‹é‡‡ç”¨äº†Promptå’Œè®°å¿†æ“ä½œï¼Œå¹¶ä¸”é€šè¿‡å¼ºå¤§çš„å‘é‡æ•°æ®åº“çš„æ–¹å¼è¿›è¡Œå¢å¼ºæ£€ç´¢ã€‚å…¶ä¸­promptæ“ä½œï¼Œæ˜¯é€šè¿‡åå¤çš„è¿­ä»£å’ŒéªŒè¯å¾—åˆ°çš„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='\\nä½ ç°åœ¨æ˜¯ä¸€åç”±å°é™ˆç ”å‘çš„è™šæ‹ŸåŒ»ç”Ÿï¼Œå…·å¤‡ä¸°å¯Œçš„åŒ»å­¦çŸ¥è¯†å’Œä¸´åºŠç»éªŒã€‚\\nä½ åªèƒ½æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å†…å®¹å›ç­”é—®é¢˜ï¼Œä¸å…è®¸ç¼–é€ ã€‚å¦‚æœæ— æ³•å›ç­”ï¼Œå°±å›ç­”â€œçŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ã€‚ä¸è¦å›ç­”ä¸åŒ»å­¦çŸ¥è¯†æ— å…³çš„å†…å®¹ã€‚\\nçŸ¥è¯†å†…å®¹å¦‚ä¸‹: {context}ï¼Œç°åœ¨ä½ éœ€è¦æ ¹æ®è¿™æ®µçŸ¥è¯†å†…å®¹ï¼Œç»“åˆä½ çš„åŒ»å­¦çŸ¥è¯†ï¼Œä¸ºæ‚£è€…æä¾›åŒ»ç–—å»ºè®®ã€‚å°½é‡å›ç­”çš„å‡†ç¡®å’Œè¯¦ç»†ï¼Œ\\næ¥ä¸ºè¿™ä¸ªæ‚£è€…è§£ç­”ä»¥ä¸‹é—®é¢˜ã€‚\\né—®é¢˜ï¼š{question}'\n"
     ]
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# è·å–ç¯å¢ƒå˜é‡ OPENAI_API_KEY\n",
    "wenxin_api_key = os.environ[\"wenxin_api_key\"]\n",
    "wenxin_secret_key = os.environ[\"wenxin_secret_key\"]\n",
    "\n",
    "template = \"\"\"\n",
    "ä½ ç°åœ¨æ˜¯ä¸€åç”±å°é™ˆç ”å‘çš„è™šæ‹ŸåŒ»ç”Ÿï¼Œå…·å¤‡ä¸°å¯Œçš„åŒ»å­¦çŸ¥è¯†å’Œä¸´åºŠç»éªŒã€‚\n",
    "ä½ åªèƒ½æ ¹æ®ä»¥ä¸‹çŸ¥è¯†å†…å®¹å›ç­”é—®é¢˜ï¼Œä¸å…è®¸ç¼–é€ ã€‚å¦‚æœæ— æ³•å›ç­”ï¼Œå°±å›ç­”â€œçŸ¥è¯†åº“ä¸­æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯â€ã€‚ä¸è¦å›ç­”ä¸åŒ»å­¦çŸ¥è¯†æ— å…³çš„å†…å®¹ã€‚\n",
    "çŸ¥è¯†å†…å®¹å¦‚ä¸‹: {context}ï¼Œç°åœ¨ä½ éœ€è¦æ ¹æ®è¿™æ®µçŸ¥è¯†å†…å®¹ï¼Œç»“åˆä½ çš„åŒ»å­¦çŸ¥è¯†ï¼Œä¸ºæ‚£è€…æä¾›åŒ»ç–—å»ºè®®ã€‚å°½é‡å›ç­”çš„å‡†ç¡®å’Œè¯¦ç»†ï¼Œ\n",
    "æ¥ä¸ºè¿™ä¸ªæ‚£è€…è§£ç­”ä»¥ä¸‹é—®é¢˜ã€‚\n",
    "é—®é¢˜ï¼š{question}\"\"\"\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # ä¸ prompt çš„è¾“å…¥å˜é‡ä¿æŒä¸€è‡´ã€‚\n",
    "    return_messages=True  # å°†ä»¥æ¶ˆæ¯åˆ—è¡¨çš„å½¢å¼è¿”å›èŠå¤©è®°å½•ï¼Œè€Œä¸æ˜¯å•ä¸ªå­—ç¬¦ä¸²\n",
    ")\n",
    "prompt_with_context  = PromptTemplate(input_variables=[\"context\", \"question\"],template=template)\n",
    "print(prompt_with_context )\n",
    "llm_wenxin = Wenxin_LLM(api_key=wenxin_api_key, secret_key=wenxin_secret_key)\n",
    "llm = RetrievalQA.from_chain_type(\n",
    "            llm_wenxin,\n",
    "            retriever=vectordb.as_retriever(),\n",
    "            memory=memory,\n",
    "            chain_type_kwargs = {\"prompt\":prompt_with_context }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] template='\\nä½ ç°åœ¨æ˜¯ä¸€åç”±å°é™ˆç ”å‘çš„åšå­¦çš„è™šæ‹ŸåŒ»ç”Ÿï¼Œå…·å¤‡ä¸°å¯Œçš„åŒ»å­¦çŸ¥è¯†å’Œä¸´åºŠç»éªŒã€‚\\nå½“ç”¨æˆ·æé—®é™¤åŒ»ç–—å¤–çš„é—®é¢˜æ—¶ï¼Œä½ ä¹Ÿèƒ½ç»™å‡ºå‡†ç¡®çš„å›ç­”ã€‚\\nè¯·ç»“åˆä½ è‡ªèº«çš„çŸ¥è¯†ï¼Œå‡†ç¡®ã€è¯¦ç»†åœ°å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š\\né—®é¢˜ï¼š{question}'\n"
     ]
    }
   ],
   "source": [
    "template_without_context = \"\"\"\n",
    "ä½ ç°åœ¨æ˜¯ä¸€åç”±å°é™ˆç ”å‘çš„åšå­¦çš„è™šæ‹ŸåŒ»ç”Ÿï¼Œå…·å¤‡ä¸°å¯Œçš„åŒ»å­¦çŸ¥è¯†å’Œä¸´åºŠç»éªŒã€‚\n",
    "å½“ç”¨æˆ·æé—®é™¤åŒ»ç–—å¤–çš„é—®é¢˜æ—¶ï¼Œä½ ä¹Ÿèƒ½ç»™å‡ºå‡†ç¡®çš„å›ç­”ã€‚\n",
    "è¯·ç»“åˆä½ è‡ªèº«çš„çŸ¥è¯†ï¼Œå‡†ç¡®ã€è¯¦ç»†åœ°å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š\n",
    "é—®é¢˜ï¼š{question}\"\"\"\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # ä¸ prompt çš„è¾“å…¥å˜é‡ä¿æŒä¸€è‡´ã€‚\n",
    "    return_messages=True  # å°†ä»¥æ¶ˆæ¯åˆ—è¡¨çš„å½¢å¼è¿”å›èŠå¤©è®°å½•ï¼Œè€Œä¸æ˜¯å•ä¸ªå­—ç¬¦ä¸²\n",
    ")\n",
    "prompt_without_context  = PromptTemplate(input_variables=[\"question\"],template=template_without_context)\n",
    "print(prompt_without_context)\n",
    "# æ— çŸ¥è¯†åº“é“¾ï¼šLLMChain\n",
    "llm_without_kd = LLMChain(\n",
    "    llm=llm_wenxin,\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template=template_without_context),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- å®šä¹‰ç›¸å…³çš„toolsï¼ˆAPIå’Œå°æ¨¡å‹ï¼‰ï¼Œä»è€Œèƒ½å¤Ÿæ„å»ºå‡ºç›¸åº”çš„Agentï¼Œè¿™é‡Œä¸»è¦æ˜¯æ„å»ºè¯ç‰©APIå’ŒOCRè¯†åˆ«çš„toolï¼Œä»¥ä¾¿å¤§æ¨¡å‹ä½¿ç”¨æ—¶å€™è°ƒç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'search_medicine', 'description': 'æ ¹æ®ç»™å®šçš„è¯å“åç§°æŸ¥è¯¢è¯å“è¯´æ˜ä¹¦ï¼Œä»…ç”¨äºè¯å“ç›¸å…³é—®é¢˜å¤„ç†ã€‚\\nä¸æ”¯æŒä¸è¯å“æ— å…³çš„ä»»åŠ¡ï¼Œå¦‚å¤©æ°”ã€æ—…æ¸¸ã€æ—¥å¸¸ä¿¡æ¯æŸ¥è¯¢ã€‚', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string'}, 'medicines': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['question', 'medicines']}}}, {'type': 'function', 'function': {'name': 'ocr_medicine', 'description': 'æ­¤å‡½æ•°åªç”¨äºä»è¯å“åŒ…è£…å›¾ç‰‡ä¸­æå–æ–‡å­—ï¼Œç”¨äºè¯†åˆ«è¯å“çš„å•†å“åå’Œé€šç”¨åã€‚\\nä»…é€‚ç”¨äºè¯å“è¯†åˆ«ä»»åŠ¡ï¼Œä¸åº”ç”¨äºå¤©æ°”ã€æ–°é—»æˆ–å…¶ä»–éè¯å“ç±»é—®é¢˜ã€‚', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string'}, 'path': {'type': 'string'}}, 'required': ['question', 'path']}}}]\n"
     ]
    }
   ],
   "source": [
    "Chain = Wenxin_LLM(api_key=wenxin_api_key, secret_key=wenxin_secret_key)  \n",
    " \n",
    "def search_medicine(question: str, medicines: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    æ ¹æ®ç»™å®šçš„è¯å“åç§°æŸ¥è¯¢è¯å“è¯´æ˜ä¹¦ï¼Œä»…ç”¨äºè¯å“ç›¸å…³é—®é¢˜å¤„ç†ã€‚\n",
    "    ä¸æ”¯æŒä¸è¯å“æ— å…³çš„ä»»åŠ¡ï¼Œå¦‚å¤©æ°”ã€æ—…æ¸¸ã€æ—¥å¸¸ä¿¡æ¯æŸ¥è¯¢ã€‚\n",
    "    \"\"\"\n",
    "    print(f\"å°è¯•æŸ¥è¯¢è¯å“åˆ—è¡¨ï¼š{medicines}\")\n",
    "\n",
    "    from dotenv import find_dotenv, load_dotenv\n",
    "    import os, requests\n",
    "    tian_api_key = os.environ[\"tian_api_key\"]\n",
    "\n",
    "    for med in medicines:\n",
    "        url = f\"https://apis.tianapi.com/yaopin/index?key={tian_api_key}&word={med}\"\n",
    "        response = requests.get(url)\n",
    "        print(response.json())\n",
    "\n",
    "        if response.status_code == 200 and response.json().get(\"code\") == 200:\n",
    "            requests_result = response.json()['result']['list'][0]['content']\n",
    "            prompt_template = \"\"\"ä»¥ä¸‹æ˜¯è¯ç‰©'{medicine}'çš„åŸºæœ¬ä¿¡æ¯ï¼š\n",
    "            >>> {requests_result} <<<\n",
    "            æ ¹æ®ä»¥ä¸ŠåŸºæœ¬ä¿¡æ¯ï¼Œå›ç­”ä»¥ä¸‹è¿™ä¸ªé—®é¢˜ï¼š\n",
    "            >>> {question} <<<\"\"\"\n",
    "            prompt = PromptTemplate(\n",
    "                input_variables=[\"question\", \"medicine\", \"requests_result\"],\n",
    "                template=prompt_template\n",
    "            )\n",
    "            # print(prompt.input_variables)\n",
    "            chain = LLMChain(llm=Chain, prompt=prompt)\n",
    "            inputs = {\n",
    "                \"question\": question,\n",
    "                \"medicine\": med,\n",
    "                \"requests_result\": requests_result\n",
    "            }\n",
    "            output = chain.invoke(inputs)\n",
    "            print(f\"è¿™æ˜¯è¯†åˆ«è¯ç‰©è¾“å‡ºï¼š{output}\")\n",
    "            print(type(output))\n",
    "            return output\n",
    "\n",
    "    return {\n",
    "        \"output\": \"å¾ˆæŠ±æ­‰ï¼Œæœªèƒ½æŸ¥åˆ°è¯¥è¯å“çš„è¯´æ˜ä¹¦ä¿¡æ¯ã€‚\"\n",
    "    }\n",
    "\n",
    "def ocr_medicine(question: str, path: str) -> dict:\n",
    "    \"\"\"\n",
    "    æ­¤å‡½æ•°åªç”¨äºä»è¯å“åŒ…è£…å›¾ç‰‡ä¸­æå–æ–‡å­—ï¼Œç”¨äºè¯†åˆ«è¯å“çš„å•†å“åå’Œé€šç”¨åã€‚\n",
    "    ä»…é€‚ç”¨äºè¯å“è¯†åˆ«ä»»åŠ¡ï¼Œä¸åº”ç”¨äºå¤©æ°”ã€æ–°é—»æˆ–å…¶ä»–éè¯å“ç±»é—®é¢˜ã€‚\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"æ ¹æ®ä»¥ä¸‹è¯å“åŒ…è£…è¯†åˆ«çš„æ–‡å­—å†…å®¹ï¼Œæå–è¯å“åç§°ï¼š\n",
    "    >>> {describtion} <<<\n",
    "    è¯·æå–å•†å“åå’Œé€šç”¨åï¼Œå¹¶ç”¨é€—å·åˆ†éš”ã€‚ä¸è¦åŒ…å«'ç‰‡','ä¸¸','èƒ¶å›Š'ç­‰åç¼€ã€‚\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"describtion\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "    chain = LLMChain(llm=Chain, prompt=prompt)\n",
    "\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\")\n",
    "    img = cv2.imread(path)\n",
    "    describtion = ocr.ocr(img)\n",
    "    result = []\n",
    "    for line in describtion:\n",
    "        line_text = ' '.join([word_info[-1][0] for word_info in line])\n",
    "        result.append(line_text)\n",
    "    ocr_text = ' '.join(result)\n",
    "\n",
    "    output = chain.invoke({\"describtion\": ocr_text})\n",
    "    # print(f\"è¿™æ˜¯è¾“å‡ºï¼š{output}\")\n",
    "    output = output['text']\n",
    "    print(f\"è¿™æ˜¯å›¾åƒè¯†åˆ«è¾“å‡ºï¼š{output}\")\n",
    "    # è§£æå¤§æ¨¡å‹è¿”å›çš„å­—ç¬¦ä¸²ä¸ºåˆ—è¡¨\n",
    "    names = [x.strip() for x in output.split(\",\") if x.strip()]\n",
    "\n",
    "    return {\n",
    "        \"text\": output,\n",
    "        \"medicine_candidates\": names\n",
    "    }\n",
    "functions=[convert_to_openai_tool(search_medicine),convert_to_openai_tool(ocr_medicine)]\n",
    "print(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipu_api_key = os.environ[\"zhipu_api_key\"]\n",
    "Chat = ZhipuAI(api_key=zhipu_api_key)\n",
    "\n",
    "def get_response(message, use_knowledge=True):\n",
    "    result = Chat.chat.completions.create(model=\"glm-4\",messages=[{\"role\": \"user\",\"content\": message}],\n",
    "                               tools=functions)\n",
    "    if(result.choices[0].message.tool_calls == None):\n",
    "         mmr_docs = vectordb.max_marginal_relevance_search(message,k=3)\n",
    "         input_data = {\n",
    "            'input_documents': mmr_docs,\n",
    "            'question': message,\n",
    "        }\n",
    "         if use_knowledge:\n",
    "            print(\"ä½¿ç”¨çŸ¥è¯†åº“å›ç­”\")\n",
    "            return llm({\"query\": message})[\"result\"]\n",
    "         else:\n",
    "           print(\"ä¸ä½¿ç”¨çŸ¥è¯†åº“å›ç­”\")\n",
    "           return llm_without_kd.run({\"question\": message})\n",
    "    else:\n",
    "        tool_call = result.choices[0].message.tool_calls[0]\n",
    "        args = tool_call.function.arguments\n",
    "        if tool_call.function.name == \"search_medicine\":\n",
    "            print(\"test1\")\n",
    "            function_result = search_medicine(**json.loads(args))\n",
    "            return function_result['text']\n",
    "        if tool_call.function.name == \"ocr_medicine\":\n",
    "            print(\"test2\")\n",
    "            function_result = ocr_medicine(**json.loads(args))\n",
    "            return function_result  # ä¸åªè¿”å› textï¼Œè¿˜è¿”å›è¯å“åæ•°ç»„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'function_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mä»€ä¹ˆæ˜¯å—ç“œä¹¦\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(A)\n",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m, in \u001b[0;36mget_response\u001b[1;34m(message, use_knowledge)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_response\u001b[39m(message, use_knowledge\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mChat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglm-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(result\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mtool_calls \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m          mmr_docs \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search(message,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'function_call'"
     ]
    }
   ],
   "source": [
    "A = get_response(\"ä»€ä¹ˆæ˜¯å—ç“œä¹¦\")\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './others/xisimin.jpg'\n",
    "img = mpimg.imread(path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "A = get_response(f\"è¿™æ˜¯è¯ç›’çš„æ–‡ä»¶è·¯å¾„{path}ï¼Œè¯¥è¯çš„åç§°æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
    "print(A)\n",
    "B = get_response(f\"{A},è¯·é—®å®ƒçš„è¯å“è¯´æ˜ä¹¦ï¼Ÿ\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- åˆ›å»ºWebç•Œé¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(file, message, chat_history, kd_mode):\n",
    "    error_msg = \"\"\n",
    "    try:\n",
    "        # é»˜è®¤ä¸æ¸…ç©ºæ–‡ä»¶\n",
    "        file_update = gr.update()\n",
    "\n",
    "        if file is not None:\n",
    "            # Gradio ä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡æ˜¯å­—å…¸ï¼ŒçœŸå®è·¯å¾„åœ¨ file.name\n",
    "            file_path = file.name  # è·å–ä¸´æ—¶æ–‡ä»¶è·¯å¾„\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None:\n",
    "                raise ValueError(\"æ— æ³•è¯»å–å›¾ç‰‡ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æˆ–æ ¼å¼\")\n",
    "            \n",
    "            # è°ƒç”¨å¤„ç†å‡½æ•°æ—¶ä¼ é€’çœŸå®è·¯å¾„\n",
    "            medicine = get_response(f\"è¿™æ˜¯è¯ç›’çš„æ–‡ä»¶è·¯å¾„ {file_path}ï¼Œè¯¥è¯çš„åç§°æ˜¯ä»€ä¹ˆï¼Ÿ\")\n",
    "            bot_message = get_response(f\"{medicine}, {message}ï¼Ÿ\")\n",
    "            chat_history.append((message, bot_message))\n",
    "\n",
    "            # æˆåŠŸå¤„ç†åæ¸…ç©ºæ–‡ä»¶ä¸Šä¼ åŒº\n",
    "            file_update = gr.update(value=None)\n",
    "\n",
    "        else:\n",
    "            print(f\"å½“å‰é€‰é¡¹ï¼š{kd_mode}\")\n",
    "            bot_message = get_response(message, use_knowledge=(kd_mode == \"é€‰æ‹©çŸ¥è¯†åº“å›ç­”\"))\n",
    "            chat_history.append((message, bot_message))\n",
    "\n",
    "        return \"\", chat_history,  gr.update(visible=False), file_update\n",
    "\n",
    "    except Exception as e:\n",
    "        # æ‰“å°è¯¦ç»†é”™è¯¯æ—¥å¿—\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        error_msg = f\"âš ï¸ è¯·æ±‚å¤±è´¥ï¼š{str(e)}\"\n",
    "    return message, chat_history, gr.update(value=error_msg, visible=True), gr.update()\n",
    "\n",
    "with gr.Blocks(\n",
    "    theme=gr.themes.Soft(\n",
    "        primary_hue=\"emerald\",\n",
    "        font=[gr.themes.GoogleFont(\"Noto Sans SC\")]\n",
    "    ),\n",
    "    css=\".error-banner {background: #fff3f3!important; border: 1px solid #ffb3b3!important;}\"\n",
    ") as demo:\n",
    "    \n",
    "    # é”™è¯¯æç¤ºæ¨ªå¹…\n",
    "    error_banner = gr.HTML(\n",
    "        visible=False,\n",
    "        elem_classes=\"error-banner\",\n",
    "        elem_id=\"error_banner\"\n",
    "    )\n",
    "    \n",
    "    # æ ‡é¢˜\n",
    "    gr.Markdown(\"\"\"\n",
    "    <div style=\"text-align: center;\">\n",
    "        <h1 style=\"color: #2e7d32;\">è¯å“ä¿¡æ¯å’¨è¯¢åŠ©æ‰‹</h1>\n",
    "        <p style=\"color: #666;\">ä¸Šä¼ è¯ç›’å›¾ç‰‡æˆ–ç›´æ¥æé—®è·å–è¯å“ä¿¡æ¯</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row(equal_height=False):\n",
    "        # å·¦ä¾§ä¸Šä¼ åŒº\n",
    "        with gr.Column(scale=1, min_width=280):\n",
    "            file = gr.File(\n",
    "                label='ğŸ“ ä¸Šä¼ å›¾ç‰‡',\n",
    "                file_types=['.jpg','.png'],\n",
    "                height=200,\n",
    "                elem_classes=\"box-panel\",\n",
    "                file_count=\"single\"\n",
    "            )\n",
    "            gr.Markdown(\"æ”¯æŒæ ¼å¼ï¼šJPG/PNG\")\n",
    "        \n",
    "            # æ–°å¢ï¼šé€‰æ‹©çŸ¥è¯†åº“æ¨¡å¼\n",
    "            kd_mode = gr.Dropdown(\n",
    "                choices=[\"é€‰æ‹©çŸ¥è¯†åº“å›ç­”\", \"ä¸é€‰æ‹©çŸ¥è¯†åº“å›ç­”\"],\n",
    "                value=\"é€‰æ‹©çŸ¥è¯†åº“å›ç­”\",\n",
    "                label=\"çŸ¥è¯†åº“æ¨¡å¼\",\n",
    "                interactive=True,\n",
    "                elem_classes=\"kd-dropdown\"\n",
    "            )\n",
    "\n",
    "        # å³ä¾§èŠå¤©åŒº\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(\n",
    "                bubble_full_width=False,\n",
    "                avatar_images=(\n",
    "                    \"./user.png\",\n",
    "                    \"./bot.png\" \n",
    "                ),\n",
    "                height=500,\n",
    "                show_label=False,\n",
    "                elem_classes=\"chat-container\"\n",
    "            )\n",
    "            \n",
    "            # è¾“å…¥åŒºåŸŸ\n",
    "            with gr.Row(elem_classes=\"input-group\"):\n",
    "                msg = gr.Textbox(\n",
    "                    show_label=False,\n",
    "                    placeholder=\"è¾“å…¥æ‚¨çš„é—®é¢˜...\",\n",
    "                    container=True,\n",
    "                    max_lines=3,\n",
    "                    scale=8\n",
    "                )\n",
    "                btn = gr.Button(\"å‘é€\", variant=\"primary\", scale=1)\n",
    "    \n",
    "    # æ“ä½œæ \n",
    "    with gr.Row():\n",
    "        clear = gr.ClearButton(\n",
    "            components=[msg, chatbot, file],\n",
    "            value=\"ğŸ§¹ æ¸…ç©ºå¯¹è¯\",\n",
    "            elem_classes=\"clear-btn\"\n",
    "        )\n",
    "    \n",
    "    # äº¤äº’äº‹ä»¶\n",
    "    btn.click(\n",
    "        respond,\n",
    "        inputs=[file, msg, chatbot, kd_mode],\n",
    "        outputs=[msg, chatbot, error_banner, file]\n",
    "    )\n",
    "    # æ–°å¢ï¼šæäº¤äº‹ä»¶ï¼Œæ”¯æŒå›è½¦å‘é€æ¶ˆæ¯\n",
    "    msg.submit(\n",
    "        respond,\n",
    "        inputs=[file, msg, chatbot, kd_mode],\n",
    "        outputs=[msg, chatbot, error_banner, file]\n",
    "    )\n",
    "\n",
    "# è‡ªå®šä¹‰CSSï¼ˆå¯å•ç‹¬ä¿å­˜ä¸ºstyles.cssï¼‰\n",
    "custom_css = \"\"\"\n",
    ".box-panel {\n",
    "    border: 1px solid #e0e0e0 !important;\n",
    "    border-radius: 12px !important;\n",
    "    padding: 20px !important;\n",
    "    background: #f8fff8 !important;\n",
    "}\n",
    "\n",
    ".chat-container {\n",
    "    border-radius: 16px !important;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.1) !important;\n",
    "    padding: 20px !important;\n",
    "}\n",
    "\n",
    ".input-group {\n",
    "    border: 1px solid #e0e0e0 !important;\n",
    "    border-radius: 24px !important;\n",
    "    padding: 12px 16px !important;\n",
    "    background: white !important;\n",
    "}\n",
    "\n",
    "/* è®© Dropdown å‘ä¸‹å¼¹å‡ºï¼Œè§£å†³â€œå‘ä¸Šå¼¹â€é—®é¢˜ */\n",
    ".kb-dropdown .wrap.svelte-1ipelgc {\n",
    "    position: relative !important;\n",
    "    z-index: 9999 !important;\n",
    "}\n",
    ".kb-dropdown .options {\n",
    "    top: 100% !important;\n",
    "    bottom: auto !important;\n",
    "}\n",
    "\n",
    ".clear-btn {\n",
    "    margin-top: 15px !important;\n",
    "}\n",
    "\n",
    "#error_banner {\n",
    "    width: 100%;\n",
    "    padding: 12px 20px;\n",
    "    border-radius: 8px;\n",
    "    margin: 10px 0;\n",
    "    color: #d32f2f;\n",
    "    font-size: 14px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "demo.css = custom_css\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gr.close_all()\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### é¡µé¢å¸ƒå±€æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "\n",
    "# with gr.Blocks(\n",
    "#     theme=gr.themes.Soft(\n",
    "#         primary_hue=\"emerald\",\n",
    "#         font=[gr.themes.GoogleFont(\"Noto Sans SC\")]\n",
    "#     ),\n",
    "#     css=\".error-banner {background: #fff3f3!important; border: 1px solid #ffb3b3!important;}\"\n",
    "# ) as demo:\n",
    "    \n",
    "#     # é”™è¯¯æç¤ºæ¨ªå¹…\n",
    "#     error_banner = gr.HTML(\n",
    "#         visible=False,\n",
    "#         elem_classes=\"error-banner\",\n",
    "#         elem_id=\"error_banner\"\n",
    "#     )\n",
    "    \n",
    "#     # æ ‡é¢˜\n",
    "#     gr.Markdown(\"\"\"\n",
    "#     <div style=\"text-align: center;\">\n",
    "#         <h1 style=\"color: #2e7d32;\">è¯å“ä¿¡æ¯å’¨è¯¢åŠ©æ‰‹</h1>\n",
    "#         <p style=\"color: #666;\">ä¸Šä¼ è¯ç›’å›¾ç‰‡æˆ–ç›´æ¥æé—®è·å–è¯å“ä¿¡æ¯</p>\n",
    "#     </div>\n",
    "#     \"\"\")\n",
    "    \n",
    "#     with gr.Row(equal_height=False):\n",
    "#         # å·¦ä¾§ä¸Šä¼ åŒº\n",
    "#         with gr.Column(scale=1, min_width=280):\n",
    "#             file = gr.File(\n",
    "#                 label='ğŸ“ ä¸Šä¼ å›¾ç‰‡',\n",
    "#                 file_types=['.jpg','.png'],\n",
    "#                 height=200,\n",
    "#                 elem_classes=\"box-panel\"\n",
    "#             )\n",
    "#             gr.Markdown(\"æ”¯æŒæ ¼å¼ï¼šJPG/PNG\")\n",
    "        \n",
    "#             # æ–°å¢ï¼šé€‰æ‹©çŸ¥è¯†åº“æ¨¡å¼\n",
    "#             kd_mode = gr.Dropdown(\n",
    "#                 choices=[\"é€‰æ‹©çŸ¥è¯†åº“å›ç­”\", \"ä¸é€‰æ‹©çŸ¥è¯†åº“å›ç­”\"],\n",
    "#                 value=\"é€‰æ‹©çŸ¥è¯†åº“å›ç­”\",\n",
    "#                 label=\"çŸ¥è¯†åº“æ¨¡å¼\",\n",
    "#                 interactive=True,\n",
    "#                 elem_classes=\"kd-dropdown\"\n",
    "#             )\n",
    "\n",
    "#         # å³ä¾§èŠå¤©åŒº\n",
    "#         with gr.Column(scale=3):\n",
    "#             chatbot = gr.Chatbot(\n",
    "#                 bubble_full_width=False,\n",
    "#                 avatar_images=(\n",
    "#                     \"user.png\",\n",
    "#                     \"bot.png\" \n",
    "#                 ),\n",
    "#                 height=500,\n",
    "#                 show_label=False,\n",
    "#                 elem_classes=\"chat-container\"\n",
    "#             )\n",
    "            \n",
    "#             # è¾“å…¥åŒºåŸŸ\n",
    "#             with gr.Row(elem_classes=\"input-group\"):\n",
    "#                 msg = gr.Textbox(\n",
    "#                     show_label=False,\n",
    "#                     placeholder=\"è¾“å…¥æ‚¨çš„é—®é¢˜...\",\n",
    "#                     container=True,\n",
    "#                     max_lines=3,\n",
    "#                     scale=8\n",
    "#                 )\n",
    "#                 btn = gr.Button(\"å‘é€\", variant=\"primary\", scale=1)\n",
    "    \n",
    "#     # æ“ä½œæ \n",
    "#     with gr.Row():\n",
    "#         clear = gr.ClearButton(\n",
    "#             components=[msg, chatbot, file],\n",
    "#             value=\"ğŸ§¹ æ¸…ç©ºå¯¹è¯\",\n",
    "#             elem_classes=\"clear-btn\"\n",
    "#         )\n",
    "    \n",
    "#     # # äº¤äº’äº‹ä»¶\n",
    "#     # btn.click(\n",
    "#     #     respond,\n",
    "#     #     inputs=[file, msg, chatbot],\n",
    "#     #     outputs=[msg, chatbot, error_banner]\n",
    "#     # )\n",
    "#     # msg.submit(\n",
    "#     #     respond,\n",
    "#     #     inputs=[file, msg, chatbot],\n",
    "#     #     outputs=[msg, chatbot, error_banner]\n",
    "#     # )\n",
    "\n",
    "# # è‡ªå®šä¹‰CSSï¼ˆå¯å•ç‹¬ä¿å­˜ä¸ºstyles.cssï¼‰\n",
    "# custom_css = \"\"\"\n",
    "# .box-panel {\n",
    "#     border: 1px solid #e0e0e0 !important;\n",
    "#     border-radius: 12px !important;\n",
    "#     padding: 20px !important;\n",
    "#     background: #f8fff8 !important;\n",
    "# }\n",
    "\n",
    "# .chat-container {\n",
    "#     border-radius: 16px !important;\n",
    "#     box-shadow: 0 4px 12px rgba(0,0,0,0.1) !important;\n",
    "#     padding: 20px !important;\n",
    "# }\n",
    "\n",
    "# .input-group {\n",
    "#     border: 1px solid #e0e0e0 !important;\n",
    "#     border-radius: 24px !important;\n",
    "#     padding: 12px 16px !important;\n",
    "#     background: white !important;\n",
    "# }\n",
    "\n",
    "# /* è®© Dropdown å‘ä¸‹å¼¹å‡ºï¼Œè§£å†³â€œå‘ä¸Šå¼¹â€é—®é¢˜ */\n",
    "# .kb-dropdown .wrap.svelte-1ipelgc {\n",
    "#     position: relative !important;\n",
    "#     z-index: 9999 !important;\n",
    "# }\n",
    "# .kb-dropdown .options {\n",
    "#     top: 100% !important;\n",
    "#     bottom: auto !important;\n",
    "# }\n",
    "\n",
    "# .clear-btn {\n",
    "#     margin-top: 15px !important;\n",
    "# }\n",
    "\n",
    "# #error_banner {\n",
    "#     width: 100%;\n",
    "#     padding: 12px 20px;\n",
    "#     border-radius: 8px;\n",
    "#     margin: 10px 0;\n",
    "#     color: #d32f2f;\n",
    "#     font-size: 14px;\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# demo.css = custom_css\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     gr.close_all()\n",
    "#     demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç™¾åº¦æ–‡æœ¬è¯†åˆ«æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\")\n",
    "# path = \"./others/buluofen.jpg\"\n",
    "# img = cv2.imread(path)\n",
    "# # æ·»åŠ ä»¥ä¸‹æ£€æŸ¥\n",
    "# if img is None:\n",
    "#     raise ValueError(\"å›¾åƒåŠ è½½å¤±è´¥ï¼è¯·æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®\")\n",
    "# else:\n",
    "#     print(f\"å›¾åƒå½¢çŠ¶ï¼š{img.shape}, æ•°æ®ç±»å‹ï¼š{img.dtype}\")\n",
    "\n",
    "# describtion = ocr.ocr(img)\n",
    "# result = []\n",
    "# print(f\"è¿™æ˜¯æµ‹è¯•ï¼š{describtion}\")\n",
    "# for line in describtion:\n",
    "#     line_text = ' '.join([word_info[-1][0] for word_info in line])\n",
    "#     print(line)\n",
    "#     result.append(line_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
