{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 导入相关的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.chains import RetrievalQA\n",
    "from zhipuai import ZhipuAI\n",
    "from typing import Dict, Any, Mapping\n",
    "from pydantic import Field\n",
    "from langchain.llms.base import LLM\n",
    "from typing import Any, List, Mapping, Optional, Dict, Union, Tuple\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import matplotlib.pyplot as plt\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "import matplotlib.image as mpimg\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import cv2\n",
    "import requests\n",
    "import os\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import LLMRequestsChain\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool \n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain.callbacks.manager import CallbackManagerForLLMRun\n",
    "from __future__ import annotations\n",
    "import logging\n",
    "from typing import Any, Dict, List, Optional\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.pydantic_v1 import BaseModel, root_validator\n",
    "from langchain.utils import get_from_dict_or_env\n",
    "from paddleocr import PaddleOCR\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义相关的LLM类：定义了一个名为 Self_LLM 的自定义 LLM 类，该类继承自 LLM。类包含访问 URL、模型名称、请求超时、温度系数、API 密钥和额外参数。提供了一个方法返回默认调用参数，包括温度和请求超时，并将这些参数与模型参数合并。另一个方法返回识别参数，将模型名称与默认参数合并。这个类用于灵活配置和访问自定义 LLM 模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_LLM(LLM):\n",
    "    # 自定义 LLM\n",
    "    url: str = \"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={api_key}&client_secret={secret_key}\"\n",
    "    model_name: str = \"gpt-3.5-turbo\"\n",
    "    # 访问时延上限\n",
    "    request_timeout: float = None\n",
    "    # 温度系数\n",
    "    temperature: float = 0.1\n",
    "    api_key: str = None\n",
    "    model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    # 定义一个返回默认参数的方法\n",
    "    @property\n",
    "    def _default_params(self) -> Dict[str, Any]:\n",
    "        \"\"\"获取调用默认参数。\"\"\"\n",
    "        normal_params = {\n",
    "            \"temperature\": self.temperature,\n",
    "            \"request_timeout\": self.request_timeout,\n",
    "        }\n",
    "        # print(type(self.model_kwargs))\n",
    "        return {**normal_params}\n",
    "\n",
    "    @property\n",
    "    def _identifying_params(self) -> Mapping[str, Any]:\n",
    "        \"\"\"Get the identifying parameters.\"\"\"\n",
    "        return {**{\"model_name\": self.model_name}, **self._default_params}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义相关的文心大模型：通过相关的apikey和secretkey得到对应的access token，并且通过access_token向文心一言的API地址发起请求，最终得到相应的服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token(api_key: str, secret_key: str):\n",
    "\n",
    "    url = f\"https://aip.baidubce.com/oauth/2.0/token?grant_type=client_credentials&client_id={api_key}&client_secret={secret_key}\"\n",
    "    payload = json.dumps(\"\")\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    return response.json().get(\"access_token\")\n",
    "\n",
    "\n",
    "class Wenxin_LLM(Self_LLM):\n",
    "    # 文心大模型的自定义 LLM\n",
    "    url: str = \"https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/ernie-4.0-turbo-8k?access_token={}\"\n",
    "    # Secret_Key\n",
    "    secret_key: str = None\n",
    "    # access_token\n",
    "    access_token: str = None\n",
    "\n",
    "    def init_access_token(self):\n",
    "        if self.api_key != None and self.secret_key != None:\n",
    "            try:\n",
    "                self.access_token = get_access_token(self.api_key, self.secret_key)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"获取 access_token 失败，请检查 Key\")\n",
    "        else:\n",
    "            print(\"API_Key 或 Secret_Key 为空，请检查 Key\")\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None,\n",
    "              run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
    "              **kwargs: Any):\n",
    "        # 如果 access_token 为空，初始化 access_token\n",
    "        if self.access_token == None:\n",
    "            self.init_access_token()\n",
    "        # API 调用 url\n",
    "        url = self.url.format(self.access_token)\n",
    "        # 配置 POST 参数\n",
    "        payload = json.dumps({\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",  # user prompt\n",
    "                    \"content\": \"{}\".format(prompt)  # 输入的 prompt\n",
    "                }\n",
    "            ],\n",
    "            'temperature': self.temperature\n",
    "        })\n",
    "        headers = {\n",
    "            'Content-Type': 'application/json'\n",
    "        }\n",
    "        # 发起请求\n",
    "        response = requests.request(\"POST\", url, headers=headers, data=payload, timeout=self.request_timeout)\n",
    "        if response.status_code == 200:\n",
    "            js = json.loads(response.text)\n",
    "            print(js)\n",
    "            return js[\"result\"]\n",
    "        else:\n",
    "            return \"请求失败\"\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"Wenxin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 测试大模型api是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 获取环境变量 OPENAI_API_KEY\n",
    "wenxin_api_key = os.environ[\"wenxin_api_key\"]\n",
    "wenxin_secret_key = os.environ[\"wenxin_secret_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'as-ibbafhmyq2', 'object': 'chat.completion', 'created': 1746586721, 'result': '你好，我是百度公司研发的知识增强大语言模型，我的中文名是文心一言，英文名是ERNIE Bot，很高兴认识你！我可以为你解答问题、创作文本、进行知识推理，如果你有需要的话，我还可以跟你一起聊天、分享笑话或者讲故事。', 'is_truncated': False, 'need_clear_history': False, 'finish_reason': 'normal', 'usage': {'prompt_tokens': 1, 'completion_tokens': 51, 'total_tokens': 52}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'你好，我是百度公司研发的知识增强大语言模型，我的中文名是文心一言，英文名是ERNIE Bot，很高兴认识你！我可以为你解答问题、创作文本、进行知识推理，如果你有需要的话，我还可以跟你一起聊天、分享笑话或者讲故事。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = Wenxin_LLM(api_key=wenxin_api_key, secret_key=wenxin_secret_key)\n",
    "llm(\"你好\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义相关的Zhipu的Embedding类：通过利用Zhipu Embedding进行相关的嵌入操作，从而实现后续将已有知识存入知识库的操作，这里的定义方法跟上述的文心一言大模型相似，所以这里就不再过多的赘述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhipuAIEmbeddings(BaseModel, Embeddings):\n",
    "    \"\"\"`Zhipuai Embeddings` embedding models.\"\"\"\n",
    "\n",
    "    client: Any\n",
    "    \"\"\"`zhipuai.ZhipuAI\"\"\"\n",
    "\n",
    "    @root_validator()\n",
    "    def validate_environment(cls, values: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        实例化ZhipuAI为values[\"client\"]\n",
    "\n",
    "        Args:\n",
    "\n",
    "            values (Dict): 包含配置信息的字典，必须包含 client 的字段.\n",
    "        Returns:\n",
    "\n",
    "            values (Dict): 包含配置信息的字典。如果环境中有zhipuai库，则将返回实例化的ZhipuAI类；否则将报错 'ModuleNotFoundError: No module named 'zhipuai''.\n",
    "        \"\"\"\n",
    "        from zhipuai import ZhipuAI\n",
    "        from dotenv import find_dotenv, load_dotenv\n",
    "        import os\n",
    "        zhipu_api_key = os.environ[\"zhipu_api_key\"]\n",
    "\n",
    "        values[\"client\"] = ZhipuAI(api_key=zhipu_api_key)\n",
    "        return values\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        生成输入文本的 embedding.\n",
    "\n",
    "        Args:\n",
    "            texts (str): 要生成 embedding 的文本.\n",
    "\n",
    "        Return:\n",
    "            embeddings (List[float]): 输入文本的 embedding，一个浮点数值列表.\n",
    "        \"\"\"\n",
    "        embeddings = self.client.embeddings.create(\n",
    "            model=\"embedding-2\",\n",
    "            input=text\n",
    "        )\n",
    "        # 单个文本的 embedding 是一个列表，包含一个字典。每个字典都有一个 'embedding' 的键，其值是浮点数列表.\n",
    "        # 因此，我们从列表中取出第一个元素（字典），然后从这个字典中获取 'embedding' 的值.\n",
    "        return embeddings.data[0].embedding\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        生成输入文本列表的 embedding.\n",
    "        Args:\n",
    "            texts (List[str]): 要生成 embedding 的文本列表.\n",
    "\n",
    "        Returns:\n",
    "            List[List[float]]: 输入列表中每个文档的 embedding 列表。每个 embedding 都表示为一个浮点值列表。\n",
    "        \"\"\"\n",
    "        return [self.embed_query(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载相关的pdf文档，然后进行相关的文档切分，这里主要是针对我们收集到的pdf文档进行相关的切分操作，从而实现了相关的数据预处理的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # 显示进度条\n",
    "from typing import List\n",
    "\n",
    "directory = './others/data/'\n",
    "# 加载 PDF\n",
    "loaders_chinese = []\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        file_path = os.path.join(root, file)\n",
    "        loaders_chinese.append(PyMuPDFLoader(file_path))\n",
    "docs = []\n",
    "for loader in loaders_chinese:\n",
    "    docs.extend(loader.load())\n",
    "# 切分文档\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=150)\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "embedding = ZhipuAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301\n"
     ]
    }
   ],
   "source": [
    "print(len(split_docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可持久化的地址"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './others/vector_db/chroma'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 删除原来的向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linux 下删除文件夹\n",
    "# !rm -rf './others/vector_db/chroma'\n",
    "# windows 下删除文件夹\n",
    "!rmdir /s /q \"./others/vector_db/chroma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 建立相关的向量数据库：利用Chroma相关的函数和对应的Embedding类进行建立相关的向量数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=split_docs[:1000],\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory  # 允许我们将persist_directory目录保存到磁盘上\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 统计向量数据库中存储的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量库中存储的数量：301\n"
     ]
    }
   ],
   "source": [
    "vectordb.persist()\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")\n",
    "print(f\"向量库中存储的数量：{vectordb._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 建立相关的基于文心一言大模型的LLM，**RAG**技术的核心代码，并且我模型采用了Prompt和记忆操作，并且通过强大的向量数据库的方式进行增强检索。其中prompt操作，是通过反复的迭代和验证得到的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='\\n你现在是一名由小陈研发的虚拟医生，具备丰富的医学知识和临床经验。\\n你只能根据以下知识内容回答问题，不允许编造。如果无法回答，就回答“知识库中没有找到相关信息”。不要回答与医学知识无关的内容。\\n知识内容如下: {context}，现在你需要根据这段知识内容，结合你的医学知识，为患者提供医疗建议。尽量回答的准确和详细，\\n来为这个患者解答以下问题。\\n问题：{question}'\n"
     ]
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 获取环境变量 OPENAI_API_KEY\n",
    "wenxin_api_key = os.environ[\"wenxin_api_key\"]\n",
    "wenxin_secret_key = os.environ[\"wenxin_secret_key\"]\n",
    "\n",
    "template = \"\"\"\n",
    "你现在是一名由小陈研发的虚拟医生，具备丰富的医学知识和临床经验。\n",
    "你只能根据以下知识内容回答问题，不允许编造。如果无法回答，就回答“知识库中没有找到相关信息”。不要回答与医学知识无关的内容。\n",
    "知识内容如下: {context}，现在你需要根据这段知识内容，结合你的医学知识，为患者提供医疗建议。尽量回答的准确和详细，\n",
    "来为这个患者解答以下问题。\n",
    "问题：{question}\"\"\"\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")\n",
    "prompt_with_context  = PromptTemplate(input_variables=[\"context\", \"question\"],template=template)\n",
    "print(prompt_with_context )\n",
    "llm_wenxin = Wenxin_LLM(api_key=wenxin_api_key, secret_key=wenxin_secret_key)\n",
    "llm = RetrievalQA.from_chain_type(\n",
    "            llm_wenxin,\n",
    "            retriever=vectordb.as_retriever(),\n",
    "            memory=memory,\n",
    "            chain_type_kwargs = {\"prompt\":prompt_with_context }\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['question'] template='\\n你现在是一名由小陈研发的博学的虚拟医生，具备丰富的医学知识和临床经验。\\n当用户提问除医疗外的问题时，你也能给出准确的回答。\\n请结合你自身的知识，准确、详细地回答以下问题：\\n问题：{question}'\n"
     ]
    }
   ],
   "source": [
    "template_without_context = \"\"\"\n",
    "你现在是一名由小陈研发的博学的虚拟医生，具备丰富的医学知识和临床经验。\n",
    "当用户提问除医疗外的问题时，你也能给出准确的回答。\n",
    "请结合你自身的知识，准确、详细地回答以下问题：\n",
    "问题：{question}\"\"\"\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # 与 prompt 的输入变量保持一致。\n",
    "    return_messages=True  # 将以消息列表的形式返回聊天记录，而不是单个字符串\n",
    ")\n",
    "prompt_without_context  = PromptTemplate(input_variables=[\"question\"],template=template_without_context)\n",
    "print(prompt_without_context)\n",
    "# 无知识库链：LLMChain\n",
    "llm_without_kd = LLMChain(\n",
    "    llm=llm_wenxin,\n",
    "    prompt=PromptTemplate(input_variables=[\"question\"], template=template_without_context),\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 定义相关的tools（API和小模型），从而能够构建出相应的Agent，这里主要是构建药物API和OCR识别的tool，以便大模型使用时候调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'function', 'function': {'name': 'search_medicine', 'description': '根据给定的药品名称查询药品说明书，仅用于药品相关问题处理。\\n不支持与药品无关的任务，如天气、旅游、日常信息查询。', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string'}, 'medicines': {'type': 'array', 'items': {'type': 'string'}}}, 'required': ['question', 'medicines']}}}, {'type': 'function', 'function': {'name': 'ocr_medicine', 'description': '此函数只用于从药品包装图片中提取文字，用于识别药品的商品名和通用名。\\n仅适用于药品识别任务，不应用于天气、新闻或其他非药品类问题。', 'parameters': {'type': 'object', 'properties': {'question': {'type': 'string'}, 'path': {'type': 'string'}}, 'required': ['question', 'path']}}}]\n"
     ]
    }
   ],
   "source": [
    "Chain = Wenxin_LLM(api_key=wenxin_api_key, secret_key=wenxin_secret_key)  \n",
    " \n",
    "def search_medicine(question: str, medicines: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    根据给定的药品名称查询药品说明书，仅用于药品相关问题处理。\n",
    "    不支持与药品无关的任务，如天气、旅游、日常信息查询。\n",
    "    \"\"\"\n",
    "    print(f\"尝试查询药品列表：{medicines}\")\n",
    "\n",
    "    from dotenv import find_dotenv, load_dotenv\n",
    "    import os, requests\n",
    "    tian_api_key = os.environ[\"tian_api_key\"]\n",
    "\n",
    "    for med in medicines:\n",
    "        url = f\"https://apis.tianapi.com/yaopin/index?key={tian_api_key}&word={med}\"\n",
    "        response = requests.get(url)\n",
    "        print(response.json())\n",
    "\n",
    "        if response.status_code == 200 and response.json().get(\"code\") == 200:\n",
    "            requests_result = response.json()['result']['list'][0]['content']\n",
    "            prompt_template = \"\"\"以下是药物'{medicine}'的基本信息：\n",
    "            >>> {requests_result} <<<\n",
    "            根据以上基本信息，回答以下这个问题：\n",
    "            >>> {question} <<<\"\"\"\n",
    "            prompt = PromptTemplate(\n",
    "                input_variables=[\"question\", \"medicine\", \"requests_result\"],\n",
    "                template=prompt_template\n",
    "            )\n",
    "            # print(prompt.input_variables)\n",
    "            chain = LLMChain(llm=Chain, prompt=prompt)\n",
    "            inputs = {\n",
    "                \"question\": question,\n",
    "                \"medicine\": med,\n",
    "                \"requests_result\": requests_result\n",
    "            }\n",
    "            output = chain.invoke(inputs)\n",
    "            print(f\"这是识别药物输出：{output}\")\n",
    "            print(type(output))\n",
    "            return output\n",
    "\n",
    "    return {\n",
    "        \"output\": \"很抱歉，未能查到该药品的说明书信息。\"\n",
    "    }\n",
    "\n",
    "def ocr_medicine(question: str, path: str) -> dict:\n",
    "    \"\"\"\n",
    "    此函数只用于从药品包装图片中提取文字，用于识别药品的商品名和通用名。\n",
    "    仅适用于药品识别任务，不应用于天气、新闻或其他非药品类问题。\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template = \"\"\"根据以下药品包装识别的文字内容，提取药品名称：\n",
    "    >>> {describtion} <<<\n",
    "    请提取商品名和通用名，并用逗号分隔。不要包含'片','丸','胶囊'等后缀。\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"describtion\"],\n",
    "        template=prompt_template\n",
    "    )\n",
    "    chain = LLMChain(llm=Chain, prompt=prompt)\n",
    "\n",
    "    ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\")\n",
    "    img = cv2.imread(path)\n",
    "    describtion = ocr.ocr(img)\n",
    "    result = []\n",
    "    for line in describtion:\n",
    "        line_text = ' '.join([word_info[-1][0] for word_info in line])\n",
    "        result.append(line_text)\n",
    "    ocr_text = ' '.join(result)\n",
    "\n",
    "    output = chain.invoke({\"describtion\": ocr_text})\n",
    "    # print(f\"这是输出：{output}\")\n",
    "    output = output['text']\n",
    "    print(f\"这是图像识别输出：{output}\")\n",
    "    # 解析大模型返回的字符串为列表\n",
    "    names = [x.strip() for x in output.split(\",\") if x.strip()]\n",
    "\n",
    "    return {\n",
    "        \"text\": output,\n",
    "        \"medicine_candidates\": names\n",
    "    }\n",
    "functions=[convert_to_openai_tool(search_medicine),convert_to_openai_tool(ocr_medicine)]\n",
    "print(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "zhipu_api_key = os.environ[\"zhipu_api_key\"]\n",
    "Chat = ZhipuAI(api_key=zhipu_api_key)\n",
    "\n",
    "def get_response(message, use_knowledge=True):\n",
    "    result = Chat.chat.completions.create(model=\"glm-4\",messages=[{\"role\": \"user\",\"content\": message}],\n",
    "                               tools=functions)\n",
    "    if(result.choices[0].message.tool_calls == None):\n",
    "         mmr_docs = vectordb.max_marginal_relevance_search(message,k=3)\n",
    "         input_data = {\n",
    "            'input_documents': mmr_docs,\n",
    "            'question': message,\n",
    "        }\n",
    "         if use_knowledge:\n",
    "            print(\"使用知识库回答\")\n",
    "            return llm({\"query\": message})[\"result\"]\n",
    "         else:\n",
    "           print(\"不使用知识库回答\")\n",
    "           return llm_without_kd.run({\"question\": message})\n",
    "    else:\n",
    "        tool_call = result.choices[0].message.tool_calls[0]\n",
    "        args = tool_call.function.arguments\n",
    "        if tool_call.function.name == \"search_medicine\":\n",
    "            print(\"test1\")\n",
    "            function_result = search_medicine(**json.loads(args))\n",
    "            return function_result['text']\n",
    "        if tool_call.function.name == \"ocr_medicine\":\n",
    "            print(\"test2\")\n",
    "            function_result = ocr_medicine(**json.loads(args))\n",
    "            return function_result  # 不只返回 text，还返回药品名数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'function_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m什么是南瓜书\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(A)\n",
      "Cell \u001b[1;32mIn[20], line 5\u001b[0m, in \u001b[0;36mget_response\u001b[1;34m(message, use_knowledge)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_response\u001b[39m(message, use_knowledge\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m----> 5\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mChat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mglm-4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                               \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(result\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mtool_calls \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m          mmr_docs \u001b[38;5;241m=\u001b[39m vectordb\u001b[38;5;241m.\u001b[39mmax_marginal_relevance_search(message,k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'function_call'"
     ]
    }
   ],
   "source": [
    "A = get_response(\"什么是南瓜书\")\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './others/xisimin.jpg'\n",
    "img = mpimg.imread(path)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "A = get_response(f\"这是药盒的文件路径{path}，该药的名称是什么？\")\n",
    "print(A)\n",
    "B = get_response(f\"{A},请问它的药品说明书？\")\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 创建Web界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def format_chat_prompt(message, chat_history):\n",
    "    prompt = \"\"\n",
    "    for turn in chat_history:\n",
    "        user_message, bot_message = turn\n",
    "        prompt = f\"{prompt}\\nUser: {user_message}\\nAssistant: {bot_message}\"\n",
    "    prompt = f\"{prompt}\\nUser: {message}\\nAssistant:\"\n",
    "    return prompt\n",
    "\n",
    "def respond(file, message, chat_history, kd_mode):\n",
    "    error_msg = \"\"\n",
    "    try:\n",
    "        # 默认不清空文件\n",
    "        file_update = gr.update()\n",
    "\n",
    "        if file is not None:\n",
    "            # Gradio 上传的文件对象是字典，真实路径在 file.name\n",
    "            file_path = file.name  # 获取临时文件路径\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None:\n",
    "                raise ValueError(\"无法读取图片，请检查文件路径或格式\")\n",
    "            \n",
    "            # 调用处理函数时传递真实路径\n",
    "            medicine = get_response(f\"这是药盒的文件路径 {file_path}，该药的名称是什么？\")\n",
    "            bot_message = get_response(f\"{medicine}, {message}？\")\n",
    "            chat_history.append((message, bot_message))\n",
    "\n",
    "            # 成功处理后清空文件上传区\n",
    "            file_update = gr.update(value=None)\n",
    "\n",
    "        else:\n",
    "            print(f\"当前选项：{kd_mode}\")\n",
    "            bot_message = get_response(message, use_knowledge=(kd_mode == \"选择知识库回答\"))\n",
    "            chat_history.append((message, bot_message))\n",
    "\n",
    "        return \"\", chat_history,  gr.update(visible=False), file_update\n",
    "\n",
    "    except Exception as e:\n",
    "        # 打印详细错误日志\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        error_msg = f\"⚠️ 请求失败：{str(e)}\"\n",
    "    return message, chat_history, gr.update(value=error_msg, visible=True), gr.update()\n",
    "\n",
    "with gr.Blocks(\n",
    "    theme=gr.themes.Soft(\n",
    "        primary_hue=\"emerald\",\n",
    "        font=[gr.themes.GoogleFont(\"Noto Sans SC\")]\n",
    "    ),\n",
    "    css=\".error-banner {background: #fff3f3!important; border: 1px solid #ffb3b3!important;}\"\n",
    ") as demo:\n",
    "    \n",
    "    # 错误提示横幅\n",
    "    error_banner = gr.HTML(\n",
    "        visible=False,\n",
    "        elem_classes=\"error-banner\",\n",
    "        elem_id=\"error_banner\"\n",
    "    )\n",
    "    \n",
    "    # 标题\n",
    "    gr.Markdown(\"\"\"\n",
    "    <div style=\"text-align: center;\">\n",
    "        <h1 style=\"color: #2e7d32;\">药品信息咨询助手</h1>\n",
    "        <p style=\"color: #666;\">上传药盒图片或直接提问获取药品信息</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row(equal_height=False):\n",
    "        # 左侧上传区\n",
    "        with gr.Column(scale=1, min_width=280):\n",
    "            file = gr.File(\n",
    "                label='📁 上传图片',\n",
    "                file_types=['.jpg','.png'],\n",
    "                height=200,\n",
    "                elem_classes=\"box-panel\",\n",
    "                file_count=\"single\"\n",
    "            )\n",
    "            gr.Markdown(\"支持格式：JPG/PNG\")\n",
    "        \n",
    "            # 新增：选择知识库模式\n",
    "            kd_mode = gr.Dropdown(\n",
    "                choices=[\"选择知识库回答\", \"不选择知识库回答\"],\n",
    "                value=\"选择知识库回答\",\n",
    "                label=\"知识库模式\",\n",
    "                interactive=True,\n",
    "                elem_classes=\"kd-dropdown\"\n",
    "            )\n",
    "\n",
    "        # 右侧聊天区\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(\n",
    "                bubble_full_width=False,\n",
    "                avatar_images=(\n",
    "                    \"./user.png\",\n",
    "                    \"./bot.png\" \n",
    "                ),\n",
    "                height=500,\n",
    "                show_label=False,\n",
    "                elem_classes=\"chat-container\"\n",
    "            )\n",
    "            \n",
    "            # 输入区域\n",
    "            with gr.Row(elem_classes=\"input-group\"):\n",
    "                msg = gr.Textbox(\n",
    "                    show_label=False,\n",
    "                    placeholder=\"输入您的问题...\",\n",
    "                    container=True,\n",
    "                    max_lines=3,\n",
    "                    scale=8\n",
    "                )\n",
    "                btn = gr.Button(\"发送\", variant=\"primary\", scale=1)\n",
    "    \n",
    "    # 操作栏\n",
    "    with gr.Row():\n",
    "        clear = gr.ClearButton(\n",
    "            components=[msg, chatbot, file],\n",
    "            value=\"🧹 清空对话\",\n",
    "            elem_classes=\"clear-btn\"\n",
    "        )\n",
    "    \n",
    "    # 交互事件\n",
    "    btn.click(\n",
    "        respond,\n",
    "        inputs=[file, msg, chatbot, kd_mode],\n",
    "        outputs=[msg, chatbot, error_banner, file]\n",
    "    )\n",
    "    # 新增：提交事件，支持回车发送消息\n",
    "    msg.submit(\n",
    "        respond,\n",
    "        inputs=[file, msg, chatbot, kd_mode],\n",
    "        outputs=[msg, chatbot, error_banner, file]\n",
    "    )\n",
    "\n",
    "# 自定义CSS（可单独保存为styles.css）\n",
    "custom_css = \"\"\"\n",
    ".box-panel {\n",
    "    border: 1px solid #e0e0e0 !important;\n",
    "    border-radius: 12px !important;\n",
    "    padding: 20px !important;\n",
    "    background: #f8fff8 !important;\n",
    "}\n",
    "\n",
    ".chat-container {\n",
    "    border-radius: 16px !important;\n",
    "    box-shadow: 0 4px 12px rgba(0,0,0,0.1) !important;\n",
    "    padding: 20px !important;\n",
    "}\n",
    "\n",
    ".input-group {\n",
    "    border: 1px solid #e0e0e0 !important;\n",
    "    border-radius: 24px !important;\n",
    "    padding: 12px 16px !important;\n",
    "    background: white !important;\n",
    "}\n",
    "\n",
    "/* 让 Dropdown 向下弹出，解决“向上弹”问题 */\n",
    ".kb-dropdown .wrap.svelte-1ipelgc {\n",
    "    position: relative !important;\n",
    "    z-index: 9999 !important;\n",
    "}\n",
    ".kb-dropdown .options {\n",
    "    top: 100% !important;\n",
    "    bottom: auto !important;\n",
    "}\n",
    "\n",
    ".clear-btn {\n",
    "    margin-top: 15px !important;\n",
    "}\n",
    "\n",
    "#error_banner {\n",
    "    width: 100%;\n",
    "    padding: 12px 20px;\n",
    "    border-radius: 8px;\n",
    "    margin: 10px 0;\n",
    "    color: #d32f2f;\n",
    "    font-size: 14px;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "demo.css = custom_css\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    gr.close_all()\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 页面布局测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gradio as gr\n",
    "\n",
    "# with gr.Blocks(\n",
    "#     theme=gr.themes.Soft(\n",
    "#         primary_hue=\"emerald\",\n",
    "#         font=[gr.themes.GoogleFont(\"Noto Sans SC\")]\n",
    "#     ),\n",
    "#     css=\".error-banner {background: #fff3f3!important; border: 1px solid #ffb3b3!important;}\"\n",
    "# ) as demo:\n",
    "    \n",
    "#     # 错误提示横幅\n",
    "#     error_banner = gr.HTML(\n",
    "#         visible=False,\n",
    "#         elem_classes=\"error-banner\",\n",
    "#         elem_id=\"error_banner\"\n",
    "#     )\n",
    "    \n",
    "#     # 标题\n",
    "#     gr.Markdown(\"\"\"\n",
    "#     <div style=\"text-align: center;\">\n",
    "#         <h1 style=\"color: #2e7d32;\">药品信息咨询助手</h1>\n",
    "#         <p style=\"color: #666;\">上传药盒图片或直接提问获取药品信息</p>\n",
    "#     </div>\n",
    "#     \"\"\")\n",
    "    \n",
    "#     with gr.Row(equal_height=False):\n",
    "#         # 左侧上传区\n",
    "#         with gr.Column(scale=1, min_width=280):\n",
    "#             file = gr.File(\n",
    "#                 label='📁 上传图片',\n",
    "#                 file_types=['.jpg','.png'],\n",
    "#                 height=200,\n",
    "#                 elem_classes=\"box-panel\"\n",
    "#             )\n",
    "#             gr.Markdown(\"支持格式：JPG/PNG\")\n",
    "        \n",
    "#             # 新增：选择知识库模式\n",
    "#             kd_mode = gr.Dropdown(\n",
    "#                 choices=[\"选择知识库回答\", \"不选择知识库回答\"],\n",
    "#                 value=\"选择知识库回答\",\n",
    "#                 label=\"知识库模式\",\n",
    "#                 interactive=True,\n",
    "#                 elem_classes=\"kd-dropdown\"\n",
    "#             )\n",
    "\n",
    "#         # 右侧聊天区\n",
    "#         with gr.Column(scale=3):\n",
    "#             chatbot = gr.Chatbot(\n",
    "#                 bubble_full_width=False,\n",
    "#                 avatar_images=(\n",
    "#                     \"user.png\",\n",
    "#                     \"bot.png\" \n",
    "#                 ),\n",
    "#                 height=500,\n",
    "#                 show_label=False,\n",
    "#                 elem_classes=\"chat-container\"\n",
    "#             )\n",
    "            \n",
    "#             # 输入区域\n",
    "#             with gr.Row(elem_classes=\"input-group\"):\n",
    "#                 msg = gr.Textbox(\n",
    "#                     show_label=False,\n",
    "#                     placeholder=\"输入您的问题...\",\n",
    "#                     container=True,\n",
    "#                     max_lines=3,\n",
    "#                     scale=8\n",
    "#                 )\n",
    "#                 btn = gr.Button(\"发送\", variant=\"primary\", scale=1)\n",
    "    \n",
    "#     # 操作栏\n",
    "#     with gr.Row():\n",
    "#         clear = gr.ClearButton(\n",
    "#             components=[msg, chatbot, file],\n",
    "#             value=\"🧹 清空对话\",\n",
    "#             elem_classes=\"clear-btn\"\n",
    "#         )\n",
    "    \n",
    "#     # # 交互事件\n",
    "#     # btn.click(\n",
    "#     #     respond,\n",
    "#     #     inputs=[file, msg, chatbot],\n",
    "#     #     outputs=[msg, chatbot, error_banner]\n",
    "#     # )\n",
    "#     # msg.submit(\n",
    "#     #     respond,\n",
    "#     #     inputs=[file, msg, chatbot],\n",
    "#     #     outputs=[msg, chatbot, error_banner]\n",
    "#     # )\n",
    "\n",
    "# # 自定义CSS（可单独保存为styles.css）\n",
    "# custom_css = \"\"\"\n",
    "# .box-panel {\n",
    "#     border: 1px solid #e0e0e0 !important;\n",
    "#     border-radius: 12px !important;\n",
    "#     padding: 20px !important;\n",
    "#     background: #f8fff8 !important;\n",
    "# }\n",
    "\n",
    "# .chat-container {\n",
    "#     border-radius: 16px !important;\n",
    "#     box-shadow: 0 4px 12px rgba(0,0,0,0.1) !important;\n",
    "#     padding: 20px !important;\n",
    "# }\n",
    "\n",
    "# .input-group {\n",
    "#     border: 1px solid #e0e0e0 !important;\n",
    "#     border-radius: 24px !important;\n",
    "#     padding: 12px 16px !important;\n",
    "#     background: white !important;\n",
    "# }\n",
    "\n",
    "# /* 让 Dropdown 向下弹出，解决“向上弹”问题 */\n",
    "# .kb-dropdown .wrap.svelte-1ipelgc {\n",
    "#     position: relative !important;\n",
    "#     z-index: 9999 !important;\n",
    "# }\n",
    "# .kb-dropdown .options {\n",
    "#     top: 100% !important;\n",
    "#     bottom: auto !important;\n",
    "# }\n",
    "\n",
    "# .clear-btn {\n",
    "#     margin-top: 15px !important;\n",
    "# }\n",
    "\n",
    "# #error_banner {\n",
    "#     width: 100%;\n",
    "#     padding: 12px 20px;\n",
    "#     border-radius: 8px;\n",
    "#     margin: 10px 0;\n",
    "#     color: #d32f2f;\n",
    "#     font-size: 14px;\n",
    "# }\n",
    "# \"\"\"\n",
    "\n",
    "# demo.css = custom_css\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     gr.close_all()\n",
    "#     demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 百度文本识别测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\")\n",
    "# path = \"./others/buluofen.jpg\"\n",
    "# img = cv2.imread(path)\n",
    "# # 添加以下检查\n",
    "# if img is None:\n",
    "#     raise ValueError(\"图像加载失败！请检查路径是否正确\")\n",
    "# else:\n",
    "#     print(f\"图像形状：{img.shape}, 数据类型：{img.dtype}\")\n",
    "\n",
    "# describtion = ocr.ocr(img)\n",
    "# result = []\n",
    "# print(f\"这是测试：{describtion}\")\n",
    "# for line in describtion:\n",
    "#     line_text = ' '.join([word_info[-1][0] for word_info in line])\n",
    "#     print(line)\n",
    "#     result.append(line_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
